from pathlib import Path

path = Path('app/tasks/document_tasks.py')
lines = path.read_text().splitlines()
start = next(i for i,l in enumerate(lines) if l.strip().startswith('def parse_document('))
# locate end before next decorator
def_end = next(i for i,l in enumerate(lines[start:], start) if l.startswith('@celery_app.task(') and i>start)
old_block = '\n'.join(lines[start:def_end])
if 'DocumentParser()' not in old_block:
    raise SystemExit('Unexpected parse_document block')

new_block = "def parse_document(self, document_id: str, job_id: str) -> Dict[str, Any]:\n    \"\"\"Parse document using LlamaParse with automatic retry\"\"\"\n    logger.info(f\"Parsing document {document_id} (attempt {self.request.retries + 1})\")\n\n    try:\n        # Update job progress\n        self.supabase.update_job(job_id, {\n            \"progress\": 10,\n            \"current_step\": \"Parsing document with LlamaParse\"\n        })\n\n        # Get document\n        document = self.supabase.get_document(document_id)\n        if not document:\n            raise ValueError(f\"Document {document_id} not found\")\n\n        # Fast path: use inline content when no source_url is available\n        source_url = (document.source_url or \"\").strip() if hasattr(document, 'source_url') else \"\"\n        inline_content = getattr(document, 'content', None)
\n        if not source_url and inline_content:\n            text_content = inline_content if isinstance(inline_content, str) else str(inline_content)\n            logger.info(\"Using inline document content for %s (%d chars)\", document_id, len(text_content))\n\n            metadata = dict(document.metadata or {})\n            parse_metadata = dict(metadata.get(\"parse_metadata\") or {})\n            parse_metadata.update({\n                \"parser\": \"inline_content\",\n                \"strategy\": document.source_type.value if hasattr(document.source_type, 'value') else str(document.source_type),\n                \"confidence\": 0.9,\n            })\n            metadata[\"parse_metadata\"] = parse_metadata\n            metadata[\"parsed_text_length\"] = len(text_content)\n\n            self.supabase.update_document(document_id, {\n                \"parse_tier\": \"inline\",\n                \"parse_confidence\": 0.9,\n                \"metadata\": metadata\n            })\n\n            self.supabase.update_job(job_id, {\n                \"progress\": 25,\n                \"current_step\": \"Document parsed using inline content\"\n            })\n\n            return {\n                \"document_id\": document_id,\n                \"text\": text_content,\n                \"metadata\": metadata,\n                \"images\": []\n            }\n\n        # Parse document via LlamaParse\n        parser = DocumentParser()\n        parse_result = parser.parse(\n            document_path=source_url or document.source_url or \"\",\n            document_name=document.name,\n            parse_tier=ParseTier.BALANCED  # Start with balanced\n        )\n\n        # Update document with parse results\n        metadata = dict(document.metadata or {})\n        metadata[\"parsed_text_length\"] = len(parse_result[\"text\"])\n        metadata[\"parse_metadata\"] = parse_result.get(\"metadata\", {})\n\n        self.supabase.update_document(document_id, {\n            \"parse_tier\": ParseTier.BALANCED.value,\n            \"parse_confidence\": parse_result.get(\"confidence\", 0.8),\n            \"metadata\": metadata\n        })\n\n        # Update job progress\n        self.supabase.update_job(job_id, {\n            \"progress\": 25,\n            \"current_step\": \"Document parsed successfully\"\n        })\n\n        return {\n            \"document_id\": document_id,\n            \"text\": parse_result[\"text\"],\n            \"metadata\": parse_result.get(\"metadata\", {}),\n            \"images\": parse_result.get(\"images\", [])\n        }\n\n    except Exception as e:\n        logger.error(f\"Document parsing failed: {str(e)}\")\n        raise\n"

lines[start:def_end] = new_block.splitlines()
path.write_text('\n'.join(lines) + '\n')
